{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-30T08:12:08.474092200Z",
     "start_time": "2025-09-30T08:12:08.462270200Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "\n",
    "def read_csv(file_path):\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, low_memory=False)\n",
    "        return df\n",
    "    except Exception:\n",
    "        return pd.read_csv(file_path, delimiter='_', low_memory=False)\n",
    "    \n",
    "def print_to_csv(file_path, results):\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        for res in results:\n",
    "            f.write(res + '\\n')\n",
    "    f.close()\n",
    "\n",
    "tables = []\n",
    "for i in range(0, 19):\n",
    "    cdf = read_csv(f'lake33/table_{i}.csv')\n",
    "    tables.append(cdf)                "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-30T08:12:12.505584200Z",
     "start_time": "2025-09-30T08:12:08.864915Z"
    }
   },
   "id": "53907d84a1b4bea3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook implements three methods to find similar columns across different tables in a dataset. The methods are:\n",
    "1. Set Containment method: Similarity between column values of different tables.\n",
    "2. Column name method: Similarity between column names of different tables. Measured in two different ways: Levenshtein distance (Shows how many single-character edits are needed to change one string into another) and Jaccard similarity on shingles.\n",
    "3. JOSIE method: Similarity between column values of different tables, using JOSIE. Creates posting lists and prints a top k list of similar columns (k=3).\n",
    "\n",
    "Thresholds have been set to 0.8, to avoid too many false positives."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "962b693105daeba0"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def setContainment(setA, setB):\n",
    "    \"\"\" Returns the containment of setA in setB \"\"\"\n",
    "    if len(setA) == 0:\n",
    "        return 0\n",
    "    return len(setA.intersection(setB)) / len(setA)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-23T15:29:38.485012Z",
     "start_time": "2025-09-23T15:29:38.478611200Z"
    }
   },
   "id": "49dc9274f7765dfc"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [10:22<00:00, 32.75s/it]\n"
     ]
    }
   ],
   "source": [
    "# Set Containment method:\n",
    "threshold = 0.8\n",
    "\n",
    "rows_list = []\n",
    "# Iterate through pairs of tables\n",
    "for i, df1 in enumerate(tqdm.tqdm(tables)):\n",
    "    for j, df2 in enumerate(tables):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        # Iterate through pairs of columns of both tables:\n",
    "        for colidx1, col1 in enumerate(df1.columns):\n",
    "            for colidx2, col2 in enumerate(df2.columns):\n",
    "                vals1 = set(df1[col1].dropna())\n",
    "                vals2 = set(df2[col2].dropna())\n",
    "                \n",
    "                sc1 = setContainment(vals1, vals2)\n",
    "                if sc1 >= threshold:\n",
    "                    dict = {}\n",
    "                    dict.update({'Dataset 1': 'Table ' + str(i), 'Column 1': str(col1), 'Dataset 2': 'Table ' + str(j), 'Column 2': str(col2), 'Set Containment': sc1})\n",
    "                    rows_list.append(dict)\n",
    "                \n",
    "result = pd.DataFrame(rows_list, columns=['Dataset 1', 'Dataset 2', 'Column 1', 'Column 2', 'Set Containment'])\n",
    "result.to_csv('outputs/set_containment_results.csv', encoding='utf-8', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-23T16:36:46.066084900Z",
     "start_time": "2025-09-23T16:26:23.805146100Z"
    }
   },
   "id": "f8d4894ff4df4915"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results method 1: (Runtime ~ 10 minutes)\n",
    "\n",
    "We notice the set containment method manages to identify many similarities between tables. For instance, it correctly captures similarities between tables 1 and 2, which appear to have similar data, even when the column titles are mismatched. This is the case for many tables, where the column names are different but the values are similar. \n",
    "\n",
    "However, this method yields a large number of false positives as well. For example, some tables appear to contain some sort of sensor data, which may have a small range of values that can potentially overlap with some other columns that have no connection to sensors, but a wide range of values. This yields a set containment value that exceeds the threshold, but the columns are not actually similar in any meaningful way.\n",
    "\n",
    "One method to mitigate this issue would be to consider the set containment relation in both directions, however that would significantly increase the computation time."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4df23169affe960a"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [01:17<00:00,  4.08s/it]\n"
     ]
    }
   ],
   "source": [
    "# Column name method\n",
    "# Two ideas: Levenshtein distance, or Jaccard similarity on shingles.\n",
    "def levenshtein(s1, s2):\n",
    "    m = len(s1)\n",
    "    n = len(s2)\n",
    "    \n",
    "    prev_row = [i for i in range(n + 1)]\n",
    "    curr_row = [0] * (n + 1)\n",
    "    \n",
    "    for i in range(1, m + 1):\n",
    "        curr_row[0] = i\n",
    "        for j in range(1, n + 1):\n",
    "            if s1[i - 1] == s2[j - 1]:\n",
    "                curr_row[j] = prev_row[j - 1]\n",
    "            else:\n",
    "                curr_row[j] = min(prev_row[j - 1], prev_row[j], curr_row[j - 1]) + 1\n",
    "        prev_row = curr_row.copy()\n",
    "    return curr_row[n]\n",
    "\n",
    "def jaccard_similarity(s1, s2, k=2):\n",
    "    def get_shingles(s, k):\n",
    "        return {s[i:i+k] for i in range(len(s) - k + 1)}\n",
    "    \n",
    "    shingles1 = get_shingles(s1, k)\n",
    "    shingles2 = get_shingles(s2, k)\n",
    "    \n",
    "    intersection = len(shingles1.intersection(shingles2))\n",
    "    union = len(shingles1.union(shingles2))\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    "\n",
    "threshold = 0.8\n",
    "rows_list = []\n",
    "for i, df1 in enumerate(tqdm.tqdm(tables)):\n",
    "    for j, df2 in enumerate(tables):\n",
    "        if i >= j:\n",
    "            continue\n",
    "        for colidx1, col1 in enumerate(df1.columns):\n",
    "            for colidx2, col2 in enumerate(df2.columns):\n",
    "                c1 = col1.lower()\n",
    "                c2 = col2.lower()\n",
    "                has_result = False\n",
    "                dict = {'Dataset 1': 'Table ' + str(i), 'Column 1': str(col1), 'Dataset 2': 'Table ' + str(j), 'Column 2': str(col2)}\n",
    "                \n",
    "                lev_ratio = (levenshtein(col1.lower(), col2.lower())) / max(len(c1), len(c2))\n",
    "                if lev_ratio <= (1 - threshold):\n",
    "                    has_result = True\n",
    "                    dict.update({'Levenshtein Ratio': 1 - lev_ratio})\n",
    "                \n",
    "                for k in range(2,6):\n",
    "                    sim = jaccard_similarity(c1, c2, k)\n",
    "                    if sim >= threshold:\n",
    "                        has_result = True\n",
    "                        dict.update({f'Jaccard (k={k})': sim})\n",
    "                if has_result:\n",
    "                    rows_list.append(dict)\n",
    "              \n",
    "result = pd.DataFrame(rows_list, columns=['Dataset 1', 'Dataset 2', 'Column 1', 'Column 2', 'Levenshtein Ratio', 'Jaccard (k=2)', 'Jaccard (k=3)', 'Jaccard (k=4)', 'Jaccard (k=5)'])\n",
    "result.to_csv('outputs/column_name_results.csv', encoding='utf-8', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-23T16:38:03.547432500Z",
     "start_time": "2025-09-23T16:36:46.073082100Z"
    }
   },
   "id": "c27ca8d14489dbb2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results method 2: (Runtime ~ 75 seconds)\n",
    "\n",
    "The column name method is faster, as we only analyse the column names instead of searching through the whole values. The Levenshtein distance method manages to capture similarities when the column names are very similar. The threshold has been set to 20% difference, which means that the strings can differ by at most 20% of the length of the longer string. This may exclude shorter strings that are similar, but works well for longer strings which may contain spelling mistakes or shortcuts.\n",
    "\n",
    "The Jaccard similarity method on shingles captures similarities when column names have similar substrings. This works well for column names that differ by many characters semantically, but share common words or abbreviations.\n",
    "\n",
    "On the other hand, if the names are completely different, both methods cannot capture any similarity between tables, leading to a large number of false negatives."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa75435dde944b9d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:04<00:00,  4.58it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:08<00:00,  2.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# JOSIE method\n",
    "from builtins import str # Reset str\n",
    "\n",
    "# Create posting lists\n",
    "postings = {}\n",
    "for i, df in enumerate(tqdm.tqdm(tables)):\n",
    "    for j, col in enumerate(df.columns):\n",
    "        vals = set(df[col].dropna())\n",
    "        for entry in vals:\n",
    "            entry = str(entry)\n",
    "            if entry not in postings:\n",
    "                postings[entry] = set()\n",
    "            postings[entry].add((i, j))\n",
    "            \n",
    "k = 3\n",
    "rows_list = []\n",
    "\n",
    "for i, df1 in enumerate(tqdm.tqdm(tables)):\n",
    "    for j, col1 in enumerate(df1.columns):\n",
    "        vals1 = set(df1[col1].dropna())\n",
    "        counter = {}\n",
    "        for val in vals1:\n",
    "            val = str(val)\n",
    "            if val in postings:\n",
    "                for (table_id, col_id) in postings[val]:\n",
    "                    if table_id == i: # Do not match within the same table\n",
    "                        continue\n",
    "                    if (table_id, col_id) not in counter:\n",
    "                        counter[(table_id, col_id)] = 0\n",
    "                    counter[(table_id, col_id)] += 1\n",
    "        sorted_counter = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
    "        has_result = False\n",
    "        dict = {'Dataset 1': 'Table ' + str(i), 'Column 1': str(col1)}\n",
    "        for ((table_id, col_id), count) in sorted_counter[:(min(len(counter), k))]:\n",
    "            has_result = True\n",
    "            dict.update({f'Similar Column {len(dict)-1}': f'Table {table_id}, Column {col_id}, Overlap: {count}'})\n",
    "        if has_result:\n",
    "            rows_list.append(dict)\n",
    "\n",
    "result = pd.DataFrame(rows_list, columns=['Dataset 1', 'Column 1', 'Similar Column 1', 'Similar Column 2', 'Similar Column 3'])\n",
    "result.to_csv('outputs/josie_results.csv', encoding='utf-8', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-30T08:13:25.363937700Z",
     "start_time": "2025-09-30T08:13:12.099579100Z"
    }
   },
   "id": "9197eb7ef36e3aa1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Results method 3: (Runtime ~ 15 seconds)\n",
    "\n",
    "JOSIE does great at creating posting lists quickly, and uses them to quickly find similar columns. It is very fast and also creates a top k list of similar columns, which is useful for potential matches.\n",
    "\n",
    "However, this method only uses overlap as a metric, which is not giving very insightful information on its own. This method works best if combined with other previous approaches, which could give a better idea if two columns are actually similar or not."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa2df32b48762d0a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
